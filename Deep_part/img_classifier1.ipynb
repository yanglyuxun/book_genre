{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile,os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import read_data \n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = \"data/img_train\"\n",
    "validation_data_dir = \"data/img_val\"\n",
    "nb_train_samples = 4125\n",
    "nb_validation_samples = 466 \n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "from pandas.io.pickle import to_pickle, read_pickle\n",
    "save_dir = 'img_classifier1/'\n",
    "import os\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% make data\n",
    "_,genre,_ = read_data.read_text_data()\n",
    "id_train,id_val = read_data.read_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(train_data_dir):\n",
    "    os.mkdir(train_data_dir)\n",
    "    os.mkdir(validation_data_dir)\n",
    "    os.mkdir(train_data_dir+'/fic')\n",
    "    os.mkdir(train_data_dir+'/nonfic')\n",
    "    os.mkdir(validation_data_dir+'/fic')\n",
    "    os.mkdir(validation_data_dir+'/nonfic')\n",
    "    with zipfile.ZipFile('data/NPR_data_covers.zip') as zf:\n",
    "        fnames = [f.filename for f in zf.infolist()]\n",
    "        fnames.pop(0)\n",
    "        ids = [f.replace('img/','').replace('.jpg','') for f in fnames]\n",
    "        for id in ids:\n",
    "            g = 'fic' if 'Fiction' in genre[id] else 'nonfic'\n",
    "            with zf.open('img/%s.jpg'%id) as f:\n",
    "                dir1 = train_data_dir if id in id_train else validation_data_dir\n",
    "                with open(dir1+'/%s/%s.jpg'%(g,id),'wb') as fout:\n",
    "                    fout.write(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "57335808/58889256 [============================>.] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#%% import model\n",
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 17,926,338\n",
      "Trainable params: 3,211,650\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "#x = Dense(128, activation=\"relu\")(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "#predictions = Dense(16, activation=\"softmax\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(inputs = [model.input], outputs = [predictions])\n",
    "\n",
    "# compile the model \n",
    "#model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6832 images belonging to 2 classes.\n",
      "Found 2930 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.1)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, \n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(save_dir+\"img_best_model.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "with open(save_dir+'text_csvlogger.csv','w') as f:\n",
    "    f.write('')\n",
    "csvlog = CSVLogger(save_dir+'text_csvlogger.csv',append=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = int(nb_train_samples/batch_size),\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = int(nb_validation_samples/batch_size),\n",
    "    callbacks = [checkpoint, csvlog])\n",
    "model_final.save(save_dir+'img_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has been saved as .py and runed. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.621595</td>\n",
       "      <td>0.774228</td>\n",
       "      <td>0.648707</td>\n",
       "      <td>0.603662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.641537</td>\n",
       "      <td>0.622195</td>\n",
       "      <td>0.632543</td>\n",
       "      <td>0.611077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.647130</td>\n",
       "      <td>0.605375</td>\n",
       "      <td>0.657549</td>\n",
       "      <td>0.587684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.634484</td>\n",
       "      <td>0.616515</td>\n",
       "      <td>0.639009</td>\n",
       "      <td>0.597593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.643482</td>\n",
       "      <td>0.602409</td>\n",
       "      <td>0.672867</td>\n",
       "      <td>0.559262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.635457</td>\n",
       "      <td>0.586569</td>\n",
       "      <td>0.650862</td>\n",
       "      <td>0.576768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.646644</td>\n",
       "      <td>0.590311</td>\n",
       "      <td>0.660560</td>\n",
       "      <td>0.570894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.640321</td>\n",
       "      <td>0.595862</td>\n",
       "      <td>0.646608</td>\n",
       "      <td>0.597417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.640564</td>\n",
       "      <td>0.592530</td>\n",
       "      <td>0.657328</td>\n",
       "      <td>0.578756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.643726</td>\n",
       "      <td>0.578213</td>\n",
       "      <td>0.672867</td>\n",
       "      <td>0.557459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.642267</td>\n",
       "      <td>0.571639</td>\n",
       "      <td>0.654095</td>\n",
       "      <td>0.570330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.641537</td>\n",
       "      <td>0.579500</td>\n",
       "      <td>0.667026</td>\n",
       "      <td>0.556436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.637160</td>\n",
       "      <td>0.582417</td>\n",
       "      <td>0.679957</td>\n",
       "      <td>0.554356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.641051</td>\n",
       "      <td>0.572345</td>\n",
       "      <td>0.643319</td>\n",
       "      <td>0.574720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.639835</td>\n",
       "      <td>0.569539</td>\n",
       "      <td>0.633479</td>\n",
       "      <td>0.598061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.647130</td>\n",
       "      <td>0.561476</td>\n",
       "      <td>0.668103</td>\n",
       "      <td>0.572845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.634728</td>\n",
       "      <td>0.575456</td>\n",
       "      <td>0.652079</td>\n",
       "      <td>0.596111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.636430</td>\n",
       "      <td>0.575335</td>\n",
       "      <td>0.692888</td>\n",
       "      <td>0.544837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.642996</td>\n",
       "      <td>0.566067</td>\n",
       "      <td>0.643319</td>\n",
       "      <td>0.568932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.642753</td>\n",
       "      <td>0.554970</td>\n",
       "      <td>0.664871</td>\n",
       "      <td>0.570898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.640321</td>\n",
       "      <td>0.554281</td>\n",
       "      <td>0.636853</td>\n",
       "      <td>0.573128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.642510</td>\n",
       "      <td>0.549067</td>\n",
       "      <td>0.723195</td>\n",
       "      <td>0.606147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.635457</td>\n",
       "      <td>0.557959</td>\n",
       "      <td>0.642241</td>\n",
       "      <td>0.599592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.663911</td>\n",
       "      <td>0.540671</td>\n",
       "      <td>0.706783</td>\n",
       "      <td>0.587825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.656372</td>\n",
       "      <td>0.553542</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.577384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.640321</td>\n",
       "      <td>0.556362</td>\n",
       "      <td>0.725216</td>\n",
       "      <td>0.567742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.635214</td>\n",
       "      <td>0.556761</td>\n",
       "      <td>0.702586</td>\n",
       "      <td>0.587788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.635944</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.700431</td>\n",
       "      <td>0.577507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.657101</td>\n",
       "      <td>0.540937</td>\n",
       "      <td>0.694748</td>\n",
       "      <td>0.603530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.667315</td>\n",
       "      <td>0.537874</td>\n",
       "      <td>0.720905</td>\n",
       "      <td>0.570300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.666342</td>\n",
       "      <td>0.542873</td>\n",
       "      <td>0.661926</td>\n",
       "      <td>0.587149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.668288</td>\n",
       "      <td>0.542801</td>\n",
       "      <td>0.698276</td>\n",
       "      <td>0.629567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.659776</td>\n",
       "      <td>0.544834</td>\n",
       "      <td>0.673491</td>\n",
       "      <td>0.585778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.681907</td>\n",
       "      <td>0.521088</td>\n",
       "      <td>0.700219</td>\n",
       "      <td>0.620402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.659047</td>\n",
       "      <td>0.543854</td>\n",
       "      <td>0.674569</td>\n",
       "      <td>0.591184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.668288</td>\n",
       "      <td>0.534692</td>\n",
       "      <td>0.708972</td>\n",
       "      <td>0.554868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.666829</td>\n",
       "      <td>0.538252</td>\n",
       "      <td>0.662716</td>\n",
       "      <td>0.579085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.684582</td>\n",
       "      <td>0.513824</td>\n",
       "      <td>0.696937</td>\n",
       "      <td>0.599326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.674125</td>\n",
       "      <td>0.531476</td>\n",
       "      <td>0.697198</td>\n",
       "      <td>0.598701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.663667</td>\n",
       "      <td>0.524722</td>\n",
       "      <td>0.713362</td>\n",
       "      <td>0.600708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.682879</td>\n",
       "      <td>0.520428</td>\n",
       "      <td>0.703501</td>\n",
       "      <td>0.591589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.667072</td>\n",
       "      <td>0.532570</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.582272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.678988</td>\n",
       "      <td>0.527511</td>\n",
       "      <td>0.723195</td>\n",
       "      <td>0.594301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.672909</td>\n",
       "      <td>0.528276</td>\n",
       "      <td>0.690733</td>\n",
       "      <td>0.564882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.655156</td>\n",
       "      <td>0.536550</td>\n",
       "      <td>0.693966</td>\n",
       "      <td>0.570840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.671936</td>\n",
       "      <td>0.524642</td>\n",
       "      <td>0.671336</td>\n",
       "      <td>0.607594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.683123</td>\n",
       "      <td>0.513630</td>\n",
       "      <td>0.695043</td>\n",
       "      <td>0.588757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.669018</td>\n",
       "      <td>0.534768</td>\n",
       "      <td>0.703501</td>\n",
       "      <td>0.570730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.667802</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.696121</td>\n",
       "      <td>0.614300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.678988</td>\n",
       "      <td>0.520136</td>\n",
       "      <td>0.660832</td>\n",
       "      <td>0.595160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss   val_acc  val_loss\n",
       "0       0  0.621595  0.774228  0.648707  0.603662\n",
       "1       1  0.641537  0.622195  0.632543  0.611077\n",
       "2       2  0.647130  0.605375  0.657549  0.587684\n",
       "3       3  0.634484  0.616515  0.639009  0.597593\n",
       "4       4  0.643482  0.602409  0.672867  0.559262\n",
       "5       5  0.635457  0.586569  0.650862  0.576768\n",
       "6       6  0.646644  0.590311  0.660560  0.570894\n",
       "7       7  0.640321  0.595862  0.646608  0.597417\n",
       "8       8  0.640564  0.592530  0.657328  0.578756\n",
       "9       9  0.643726  0.578213  0.672867  0.557459\n",
       "10     10  0.642267  0.571639  0.654095  0.570330\n",
       "11     11  0.641537  0.579500  0.667026  0.556436\n",
       "12     12  0.637160  0.582417  0.679957  0.554356\n",
       "13     13  0.641051  0.572345  0.643319  0.574720\n",
       "14     14  0.639835  0.569539  0.633479  0.598061\n",
       "15     15  0.647130  0.561476  0.668103  0.572845\n",
       "16     16  0.634728  0.575456  0.652079  0.596111\n",
       "17     17  0.636430  0.575335  0.692888  0.544837\n",
       "18     18  0.642996  0.566067  0.643319  0.568932\n",
       "19     19  0.642753  0.554970  0.664871  0.570898\n",
       "20     20  0.640321  0.554281  0.636853  0.573128\n",
       "21     21  0.642510  0.549067  0.723195  0.606147\n",
       "22     22  0.635457  0.557959  0.642241  0.599592\n",
       "23     23  0.663911  0.540671  0.706783  0.587825\n",
       "24     24  0.656372  0.553542  0.715517  0.577384\n",
       "25     25  0.640321  0.556362  0.725216  0.567742\n",
       "26     26  0.635214  0.556761  0.702586  0.587788\n",
       "27     27  0.635944  0.552200  0.700431  0.577507\n",
       "28     28  0.657101  0.540937  0.694748  0.603530\n",
       "29     29  0.667315  0.537874  0.720905  0.570300\n",
       "30     30  0.666342  0.542873  0.661926  0.587149\n",
       "31     31  0.668288  0.542801  0.698276  0.629567\n",
       "32     32  0.659776  0.544834  0.673491  0.585778\n",
       "33     33  0.681907  0.521088  0.700219  0.620402\n",
       "34     34  0.659047  0.543854  0.674569  0.591184\n",
       "35     35  0.668288  0.534692  0.708972  0.554868\n",
       "36     36  0.666829  0.538252  0.662716  0.579085\n",
       "37     37  0.684582  0.513824  0.696937  0.599326\n",
       "38     38  0.674125  0.531476  0.697198  0.598701\n",
       "39     39  0.663667  0.524722  0.713362  0.600708\n",
       "40     40  0.682879  0.520428  0.703501  0.591589\n",
       "41     41  0.667072  0.532570  0.656250  0.582272\n",
       "42     42  0.678988  0.527511  0.723195  0.594301\n",
       "43     43  0.672909  0.528276  0.690733  0.564882\n",
       "44     44  0.655156  0.536550  0.693966  0.570840\n",
       "45     45  0.671936  0.524642  0.671336  0.607594\n",
       "46     46  0.683123  0.513630  0.695043  0.588757\n",
       "47     47  0.669018  0.534768  0.703501  0.570730\n",
       "48     48  0.667802  0.529032  0.696121  0.614300\n",
       "49     49  0.678988  0.520136  0.660832  0.595160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(save_dir+'text_csvlogger.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
