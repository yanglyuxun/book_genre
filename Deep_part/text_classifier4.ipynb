{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used the pre-trained glove embedding model in this trial.\n",
    "Add Convolution layers.\n",
    "Change tanh to sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_data \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.pickle import to_pickle, read_pickle\n",
    "save_dir = 'text_classifier4/'\n",
    "import os\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% imbeding vectors\n",
    "#download\n",
    "glove_dir = 'glove_data/'\n",
    "if not os.path.exists(glove_dir):\n",
    "    os.mkdir(glove_dir)\n",
    "if not os.path.exists(glove_dir+'glove.6B.zip'):\n",
    "    import subprocess\n",
    "    subprocess.run([\"wget\",'-P'+glove_dir, \"http://nlp.stanford.edu/data/glove.6B.zip\"])\n",
    "    print('downloaded')\n",
    "if not os.path.exists(glove_dir+'glove.6B.50d.txt'):\n",
    "    import zipfile\n",
    "    zip_ref = zipfile.ZipFile(glove_dir+'glove.6B.zip', 'r')\n",
    "    zip_ref.extractall(glove_dir)\n",
    "    zip_ref.close()\n",
    "    print('unziped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(glove_dir+'glove.6B.50d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169991\n"
     ]
    }
   ],
   "source": [
    "#%% first steps\n",
    "books,genre,excerpt = read_data.read_text_data()\n",
    "id_train,id_val = read_data.read_ids()\n",
    "\n",
    "MAX_WORDS = 8000\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(excerpt.values())\n",
    "sequences = tokenizer.texts_to_sequences(excerpt.values())\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "to_pickle(tokenizer, save_dir+'text_tokenizer.pickle')\n",
    "print(len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16bf8c2978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = [len(s) for s in sequences]\n",
    "sns.distplot(lens)\n",
    "plt.xlim((0,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (4166, 4000)\n",
      "Shape of label tensor: (4166, 1)\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = 4000\n",
    "data = pad_sequences(sequences, maxlen=MAXLEN)\n",
    "\n",
    "#labels = to_categorical(np.asarray(labels))\n",
    "labels = ['Fiction' in genre[id] for id in excerpt.keys()]\n",
    "labels = np.array(labels).reshape((-1,1))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 4000) (2922, 1) (1244, 4000) (1244, 1)\n"
     ]
    }
   ],
   "source": [
    "# split the data into a training set and a validation set\n",
    "\n",
    "train_index = [id in id_train for id in excerpt.keys()]\n",
    "val_index = [id in id_val for id in excerpt.keys()]\n",
    "x_train = data[train_index]\n",
    "y_train = labels[train_index]\n",
    "x_val = data[val_index]\n",
    "y_val = labels[val_index]\n",
    "print(x_train.shape,y_train.shape,x_val.shape,y_val.shape)\n",
    "\n",
    "to_pickle((x_train, y_train, x_val, y_val),save_dir+'text_dataset.pc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding layer\n",
    "embedding_vecor_length = 50 # this is determined by the glove data!!!\n",
    "num_words = min(MAX_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, embedding_vecor_length))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            embedding_vecor_length,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAXLEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4000, 50)          400000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 3998, 32)          4832      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1999, 32)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100)               33200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 438,133\n",
      "Trainable params: 38,133\n",
      "Non-trainable params: 400,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(50,dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_dir+\"text_best_model.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "#early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "with open(save_dir+'text_csvlogger.csv','w') as f:\n",
    "    f.write('')\n",
    "csvlog = CSVLogger(save_dir+'text_csvlogger.csv',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2922 samples, validate on 1244 samples\n",
      "Epoch 1/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.6520 - acc: 0.6354Epoch 00000: val_acc improved from -inf to 0.66238, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 168s - loss: 0.6518 - acc: 0.6359 - val_loss: 0.6185 - val_acc: 0.6624\n",
      "Epoch 2/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.5928 - acc: 0.6691Epoch 00001: val_acc improved from 0.66238 to 0.74437, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.5907 - acc: 0.6708 - val_loss: 0.4847 - val_acc: 0.7444\n",
      "Epoch 3/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.5394 - acc: 0.7132Epoch 00002: val_acc improved from 0.74437 to 0.75804, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.5392 - acc: 0.7146 - val_loss: 0.5402 - val_acc: 0.7580\n",
      "Epoch 4/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.5354 - acc: 0.7288Epoch 00003: val_acc improved from 0.75804 to 0.76286, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.5359 - acc: 0.7286 - val_loss: 0.4484 - val_acc: 0.7629\n",
      "Epoch 5/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4939 - acc: 0.7490Epoch 00004: val_acc improved from 0.76286 to 0.77653, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.4928 - acc: 0.7502 - val_loss: 0.4317 - val_acc: 0.7765\n",
      "0.776527331381\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=64,\n",
    "          callbacks = [checkpoint, csvlog],\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "#scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "#print(\"Accuracy: %f%%\" % (scores[1]*100))\n",
    "\n",
    "model.save(save_dir+'text_last_model.h5')\n",
    "print(checkpoint.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2922 samples, validate on 1244 samples\n",
      "Epoch 1/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4816 - acc: 0.7608Epoch 00000: val_acc improved from 0.77653 to 0.77974, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.4803 - acc: 0.7611 - val_loss: 0.4229 - val_acc: 0.7797\n",
      "Epoch 2/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4968 - acc: 0.7552Epoch 00001: val_acc improved from 0.77974 to 0.80466, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.4948 - acc: 0.7567 - val_loss: 0.4151 - val_acc: 0.8047\n",
      "Epoch 3/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4876 - acc: 0.7542Epoch 00002: val_acc did not improve\n",
      "2922/2922 [==============================] - 171s - loss: 0.4867 - acc: 0.7543 - val_loss: 0.4592 - val_acc: 0.7556\n",
      "Epoch 4/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4914 - acc: 0.7604Epoch 00003: val_acc did not improve\n",
      "2922/2922 [==============================] - 171s - loss: 0.4924 - acc: 0.7598 - val_loss: 0.5468 - val_acc: 0.6977\n",
      "Epoch 5/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4690 - acc: 0.7760Epoch 00004: val_acc did not improve\n",
      "2922/2922 [==============================] - 171s - loss: 0.4668 - acc: 0.7779 - val_loss: 0.4091 - val_acc: 0.8023\n",
      "0.804662379613\n"
     ]
    }
   ],
   "source": [
    "#%% continue training\n",
    "\n",
    "#model = load_model(save_dir+'text_last_model.h5')\n",
    "#x_train, y_train, x_val, y_val = read_pickle(save_dir+'text_dataset.pc')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64,\n",
    "          callbacks = [checkpoint, csvlog],\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "model.save(save_dir+'text_last_model.h5')\n",
    "print(checkpoint.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2922 samples, validate on 1244 samples\n",
      "Epoch 1/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4804 - acc: 0.7781Epoch 00000: val_acc did not improve\n",
      "2922/2922 [==============================] - 171s - loss: 0.4798 - acc: 0.7786 - val_loss: 0.5293 - val_acc: 0.7315\n",
      "Epoch 2/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4956 - acc: 0.7545Epoch 00001: val_acc did not improve\n",
      "2922/2922 [==============================] - 170s - loss: 0.4952 - acc: 0.7550 - val_loss: 0.4200 - val_acc: 0.7990\n",
      "Epoch 3/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4454 - acc: 0.7875Epoch 00002: val_acc improved from 0.80466 to 0.80707, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 170s - loss: 0.4442 - acc: 0.7882 - val_loss: 0.4094 - val_acc: 0.8071\n",
      "Epoch 4/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4411 - acc: 0.7917Epoch 00003: val_acc improved from 0.80707 to 0.81270, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.4401 - acc: 0.7926 - val_loss: 0.4088 - val_acc: 0.8127\n",
      "Epoch 5/5\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4393 - acc: 0.7993Epoch 00004: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4382 - acc: 0.8001 - val_loss: 0.3953 - val_acc: 0.8111\n",
      "0.812700964822\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=64,\n",
    "          callbacks = [checkpoint, csvlog],\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "model.save(save_dir+'text_last_model.h5')\n",
    "print(checkpoint.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2922 samples, validate on 1244 samples\n",
      "Epoch 1/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.5082 - acc: 0.7688Epoch 00000: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.5072 - acc: 0.7690 - val_loss: 0.4624 - val_acc: 0.7902\n",
      "Epoch 2/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4496 - acc: 0.7875Epoch 00001: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4507 - acc: 0.7871 - val_loss: 0.4250 - val_acc: 0.8023\n",
      "Epoch 3/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4331 - acc: 0.7983Epoch 00002: val_acc improved from 0.81270 to 0.81511, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.4334 - acc: 0.7981 - val_loss: 0.4057 - val_acc: 0.8151\n",
      "Epoch 4/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4164 - acc: 0.8090Epoch 00003: val_acc improved from 0.81511 to 0.82235, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.4147 - acc: 0.8101 - val_loss: 0.3972 - val_acc: 0.8223\n",
      "Epoch 5/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4846 - acc: 0.7427Epoch 00004: val_acc did not improve\n",
      "2922/2922 [==============================] - 170s - loss: 0.4837 - acc: 0.7440 - val_loss: 0.4761 - val_acc: 0.7307\n",
      "Epoch 6/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4562 - acc: 0.7729Epoch 00005: val_acc did not improve\n",
      "2922/2922 [==============================] - 170s - loss: 0.4552 - acc: 0.7741 - val_loss: 0.3934 - val_acc: 0.8135\n",
      "Epoch 7/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4121 - acc: 0.8069Epoch 00006: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.4099 - acc: 0.8084 - val_loss: 0.4033 - val_acc: 0.8175\n",
      "Epoch 8/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4158 - acc: 0.8083Epoch 00007: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.4156 - acc: 0.8073 - val_loss: 0.3972 - val_acc: 0.8151\n",
      "Epoch 9/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.5385 - acc: 0.7292Epoch 00008: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.5389 - acc: 0.7283 - val_loss: 0.5205 - val_acc: 0.6986\n",
      "Epoch 10/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.5708 - acc: 0.6969Epoch 00009: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.5706 - acc: 0.6982 - val_loss: 0.5638 - val_acc: 0.7500\n",
      "Epoch 11/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4977 - acc: 0.7531Epoch 00010: val_acc did not improve\n",
      "2922/2922 [==============================] - 170s - loss: 0.4967 - acc: 0.7539 - val_loss: 0.4301 - val_acc: 0.7805\n",
      "Epoch 12/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4480 - acc: 0.7788Epoch 00011: val_acc improved from 0.82235 to 0.82395, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 170s - loss: 0.4468 - acc: 0.7789 - val_loss: 0.3855 - val_acc: 0.8240\n",
      "Epoch 13/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4355 - acc: 0.7882Epoch 00012: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4345 - acc: 0.7892 - val_loss: 0.4863 - val_acc: 0.7395\n",
      "Epoch 14/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4237 - acc: 0.8003Epoch 00013: val_acc improved from 0.82395 to 0.83119, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 168s - loss: 0.4230 - acc: 0.8015 - val_loss: 0.3861 - val_acc: 0.8312\n",
      "Epoch 15/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4090 - acc: 0.8101Epoch 00014: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4106 - acc: 0.8090 - val_loss: 0.4000 - val_acc: 0.8215\n",
      "Epoch 16/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4137 - acc: 0.8035Epoch 00015: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4143 - acc: 0.8042 - val_loss: 0.5121 - val_acc: 0.7363\n",
      "Epoch 17/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4571 - acc: 0.7597Epoch 00016: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.4567 - acc: 0.7601 - val_loss: 0.4444 - val_acc: 0.7701\n",
      "Epoch 18/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4344 - acc: 0.7892Epoch 00017: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4348 - acc: 0.7885 - val_loss: 0.4242 - val_acc: 0.8039\n",
      "Epoch 19/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4121 - acc: 0.8090Epoch 00018: val_acc did not improve\n",
      "2922/2922 [==============================] - 170s - loss: 0.4117 - acc: 0.8090 - val_loss: 0.4012 - val_acc: 0.8095\n",
      "Epoch 20/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3982 - acc: 0.8111Epoch 00019: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3986 - acc: 0.8104 - val_loss: 0.3965 - val_acc: 0.8175\n",
      "Epoch 21/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4001 - acc: 0.8111Epoch 00020: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4010 - acc: 0.8111 - val_loss: 0.3882 - val_acc: 0.8248\n",
      "Epoch 22/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4331 - acc: 0.7878Epoch 00021: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4334 - acc: 0.7868 - val_loss: 0.4118 - val_acc: 0.8039\n",
      "Epoch 23/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3966 - acc: 0.8122Epoch 00022: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3951 - acc: 0.8135 - val_loss: 0.4274 - val_acc: 0.7918\n",
      "Epoch 24/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3924 - acc: 0.8066Epoch 00023: val_acc did not improve\n",
      "2922/2922 [==============================] - 170s - loss: 0.3936 - acc: 0.8060 - val_loss: 0.4502 - val_acc: 0.7661\n",
      "Epoch 25/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4987 - acc: 0.7851Epoch 00024: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.4975 - acc: 0.7847 - val_loss: 0.3866 - val_acc: 0.8167\n",
      "Epoch 26/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4288 - acc: 0.7962Epoch 00025: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.4281 - acc: 0.7967 - val_loss: 0.4041 - val_acc: 0.8079\n",
      "Epoch 27/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3982 - acc: 0.8080Epoch 00026: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3993 - acc: 0.8077 - val_loss: 0.3877 - val_acc: 0.8240\n",
      "Epoch 28/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3936 - acc: 0.8087Epoch 00027: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3958 - acc: 0.8066 - val_loss: 0.4103 - val_acc: 0.8095\n",
      "Epoch 29/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4149 - acc: 0.8063Epoch 00028: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.4155 - acc: 0.8053 - val_loss: 0.4522 - val_acc: 0.7572\n",
      "Epoch 30/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.4222 - acc: 0.8080Epoch 00029: val_acc did not improve\n",
      "2922/2922 [==============================] - 170s - loss: 0.4210 - acc: 0.8087 - val_loss: 0.3963 - val_acc: 0.8159\n",
      "Epoch 31/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3919 - acc: 0.8212Epoch 00030: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3938 - acc: 0.8203 - val_loss: 0.3903 - val_acc: 0.8127\n",
      "Epoch 32/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3863 - acc: 0.8236Epoch 00031: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3849 - acc: 0.8251 - val_loss: 0.3811 - val_acc: 0.8248\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3757 - acc: 0.8281Epoch 00032: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3777 - acc: 0.8279 - val_loss: 0.3857 - val_acc: 0.8248\n",
      "Epoch 34/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3951 - acc: 0.8149Epoch 00033: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3963 - acc: 0.8142 - val_loss: 0.3912 - val_acc: 0.8240\n",
      "Epoch 35/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3673 - acc: 0.8302Epoch 00034: val_acc improved from 0.83119 to 0.83280, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.3669 - acc: 0.8299 - val_loss: 0.3726 - val_acc: 0.8328\n",
      "Epoch 36/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3722 - acc: 0.8323Epoch 00035: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3729 - acc: 0.8320 - val_loss: 0.3829 - val_acc: 0.8240\n",
      "Epoch 37/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3708 - acc: 0.8285Epoch 00036: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3702 - acc: 0.8289 - val_loss: 0.3860 - val_acc: 0.8248\n",
      "Epoch 38/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3701 - acc: 0.8257Epoch 00037: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3685 - acc: 0.8268 - val_loss: 0.3875 - val_acc: 0.8191\n",
      "Epoch 39/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3642 - acc: 0.8365Epoch 00038: val_acc improved from 0.83280 to 0.83682, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 168s - loss: 0.3635 - acc: 0.8368 - val_loss: 0.3763 - val_acc: 0.8368\n",
      "Epoch 40/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3593 - acc: 0.8438Epoch 00039: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3578 - acc: 0.8450 - val_loss: 0.3887 - val_acc: 0.8248\n",
      "Epoch 41/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3666 - acc: 0.8295Epoch 00040: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3668 - acc: 0.8296 - val_loss: 0.3688 - val_acc: 0.8328\n",
      "Epoch 42/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3584 - acc: 0.8413Epoch 00041: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3595 - acc: 0.8409 - val_loss: 0.3861 - val_acc: 0.8248\n",
      "Epoch 43/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3779 - acc: 0.8326Epoch 00042: val_acc improved from 0.83682 to 0.84084, saving model to text_classifier4/text_best_model.h5\n",
      "2922/2922 [==============================] - 169s - loss: 0.3780 - acc: 0.8323 - val_loss: 0.3807 - val_acc: 0.8408\n",
      "Epoch 44/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3455 - acc: 0.8490Epoch 00043: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3458 - acc: 0.8487 - val_loss: 0.3793 - val_acc: 0.8328\n",
      "Epoch 45/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3464 - acc: 0.8465Epoch 00044: val_acc did not improve\n",
      "2922/2922 [==============================] - 169s - loss: 0.3486 - acc: 0.8450 - val_loss: 0.3843 - val_acc: 0.8207\n",
      "Epoch 46/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3474 - acc: 0.8410Epoch 00045: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3487 - acc: 0.8398 - val_loss: 0.3886 - val_acc: 0.8143\n",
      "Epoch 47/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3464 - acc: 0.8486Epoch 00046: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3486 - acc: 0.8467 - val_loss: 0.3706 - val_acc: 0.8328\n",
      "Epoch 48/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3458 - acc: 0.8483Epoch 00047: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3439 - acc: 0.8498 - val_loss: 0.3749 - val_acc: 0.8368\n",
      "Epoch 49/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3350 - acc: 0.8490Epoch 00048: val_acc did not improve\n",
      "2922/2922 [==============================] - 168s - loss: 0.3339 - acc: 0.8498 - val_loss: 0.3712 - val_acc: 0.8400\n",
      "Epoch 50/50\n",
      "2880/2922 [============================>.] - ETA: 2s - loss: 0.3261 - acc: 0.8590Epoch 00049: val_acc did not improve\n",
      "2922/2922 [==============================] - 167s - loss: 0.3267 - acc: 0.8583 - val_loss: 0.3787 - val_acc: 0.8344\n",
      "0.84083601267\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=64,\n",
    "          callbacks = [checkpoint, csvlog],\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "model.save(save_dir+'text_last_model.h5')\n",
    "print(checkpoint.best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
